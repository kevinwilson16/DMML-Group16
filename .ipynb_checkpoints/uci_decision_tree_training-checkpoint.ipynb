{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# UCI Breast Cancer Dataset - Decision Tree Model Training\n",
        "\n",
        "## Table of Contents\n",
        "1. Load Preprocessed Data\n",
        "2. Train Decision Tree Model\n",
        "3. Evaluate Performance\n",
        "4. Confusion Matrix & Classification Report\n",
        "5. ROC Curve Analysis\n",
        "6. Feature Importance Analysis\n",
        "7. Hyperparameter Tuning with Grid Search\n",
        "8. Visualize Decision Tree\n",
        "9. Save Best Model\n",
        "10. Make Predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import os\n",
        "from time import time\n",
        "\n",
        "# Decision Tree and model selection\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "\n",
        "# Evaluation metrics\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, \n",
        "    precision_score, \n",
        "    recall_score, \n",
        "    f1_score,\n",
        "    confusion_matrix, \n",
        "    classification_report,\n",
        "    roc_auc_score,\n",
        "    roc_curve\n",
        ")\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Loading Previously Preprocessed Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load preprocessed data\n",
        "print(\"Loading preprocessed data...\")\n",
        "\n",
        "X_train = pd.read_csv('data/processed/X_train_scaled.csv')\n",
        "y_train = pd.read_csv('data/processed/y_train.csv')\n",
        "X_test = pd.read_csv('data/processed/X_test_scaled.csv')\n",
        "y_test = pd.read_csv('data/processed/y_test.csv')\n",
        "\n",
        "# Load feature names\n",
        "with open('data/processed/feature_names.txt', 'r') as f:\n",
        "    feature_names = [line.strip() for line in f.readlines() if line.strip()]\n",
        "\n",
        "# Convert to numpy arrays\n",
        "y_train = y_train.values.ravel()\n",
        "y_test = y_test.values.ravel()\n",
        "\n",
        "print(f\"✓ Data loaded successfully!\")\n",
        "print(f\"\\nDataset Information:\")\n",
        "print(f\"  Training samples: {X_train.shape[0]}\")\n",
        "print(f\"  Testing samples: {X_test.shape[0]}\")\n",
        "print(f\"  Number of features: {X_train.shape[1]}\")\n",
        "print(f\"\\nClass Distribution:\")\n",
        "print(f\"  Training - Benign: {np.sum(y_train == 0)}, Malignant: {np.sum(y_train == 1)}\")\n",
        "print(f\"  Testing - Benign: {np.sum(y_test == 0)}, Malignant: {np.sum(y_test == 1)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Train Basic Decision Tree Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create and train Decision Tree model\n",
        "print(\"Training Decision Tree model...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "start_time = time()\n",
        "\n",
        "# Initialize Decision Tree classifier\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "training_time = time() - start_time\n",
        "\n",
        "print(f\"Model trained successfully in {training_time:.2f} seconds!\")\n",
        "print(f\"\\nModel Parameters:\")\n",
        "print(f\"  Max Depth: {dt_model.max_depth}\")\n",
        "print(f\"  Min Samples Split: {dt_model.min_samples_split}\")\n",
        "print(f\"  Min Samples Leaf: {dt_model.min_samples_leaf}\")\n",
        "print(f\"  Criterion: {dt_model.criterion}\")\n",
        "print(f\"  Number of Leaves: {dt_model.get_n_leaves()}\")\n",
        "print(f\"  Tree Depth: {dt_model.get_depth()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Make Predictions and Evaluate Performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "y_pred = dt_model.predict(X_test)\n",
        "y_pred_proba = dt_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DECISION TREE MODEL PERFORMANCE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nAccuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "print(f\"Precision: {precision:.4f} ({precision*100:.2f}%)\")\n",
        "print(f\"Recall:    {recall:.4f} ({recall*100:.2f}%)\")\n",
        "print(f\"F1-Score:  {f1:.4f} ({f1*100:.2f}%)\")\n",
        "print(f\"ROC-AUC:   {roc_auc:.4f} ({roc_auc*100:.2f}%)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Cross-validation score\n",
        "cv_scores = cross_val_score(dt_model, X_train, y_train, cv=5, scoring='accuracy')\n",
        "print(f\"\\n5-Fold Cross-Validation Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Confusion Matrix Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
        "            xticklabels=['Benign (0)', 'Malignant (1)'],\n",
        "            yticklabels=['Benign (0)', 'Malignant (1)'],\n",
        "            annot_kws={'size': 16, 'weight': 'bold'})\n",
        "plt.title('Confusion Matrix - Decision Tree Model', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Actual', fontsize=12)\n",
        "plt.xlabel('Predicted', fontsize=12)\n",
        "\n",
        "# Add text annotations\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "plt.text(0.5, -0.15, f'True Negatives: {tn}', ha='center', transform=plt.gca().transAxes, fontsize=10)\n",
        "plt.text(0.5, -0.20, f'False Positives: {fp}', ha='center', transform=plt.gca().transAxes, fontsize=10)\n",
        "plt.text(0.5, -0.25, f'False Negatives: {fn}', ha='center', transform=plt.gca().transAxes, fontsize=10)\n",
        "plt.text(0.5, -0.30, f'True Positives: {tp}', ha='center', transform=plt.gca().transAxes, fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nConfusion Matrix Breakdown:\")\n",
        "print(f\"  True Negatives (Correct Benign):    {tn}\")\n",
        "print(f\"  False Positives (Benign as Malignant): {fp}\")\n",
        "print(f\"  False Negatives (Malignant as Benign): {fn}\")\n",
        "print(f\"  True Positives (Correct Malignant):  {tp}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Detailed Classification Report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print detailed classification report\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DETAILED CLASSIFICATION REPORT\")\n",
        "print(\"=\"*60)\n",
        "print(classification_report(y_test, y_pred, \n",
        "                          target_names=['Benign (0)', 'Malignant (1)'],\n",
        "                          digits=4))\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. ROC Curve Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.plot(fpr, tpr, color='#2ecc71', linewidth=3, label=f'Decision Tree (AUC = {roc_auc:.4f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Random Classifier (AUC = 0.5000)')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate', fontsize=12, fontweight='bold')\n",
        "plt.ylabel('True Positive Rate', fontsize=12, fontweight='bold')\n",
        "plt.title('ROC Curve - Decision Tree Model', fontsize=14, fontweight='bold')\n",
        "plt.legend(loc=\"lower right\", fontsize=11)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nROC-AUC Score: {roc_auc:.4f}\")\n",
        "print(f\"  This means the model has a {roc_auc*100:.2f}% chance of correctly distinguishing\")\n",
        "print(f\"  between benign and malignant cases.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Feature Importance Analysis\n",
        "\n",
        "One of the key advantages of Decision Trees is interpretability through feature importance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get feature importances\n",
        "feature_importances = pd.DataFrame({\n",
        "    'feature': feature_names,\n",
        "    'importance': dt_model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nTop 10 Most Important Features:\")\n",
        "print(feature_importances.head(10).to_string(index=False))\n",
        "\n",
        "# Visualize top 15 features\n",
        "plt.figure(figsize=(12, 8))\n",
        "top_features = feature_importances.head(15)\n",
        "plt.barh(range(len(top_features)), top_features['importance'], color='#3498db')\n",
        "plt.yticks(range(len(top_features)), top_features['feature'])\n",
        "plt.xlabel('Importance', fontsize=12, fontweight='bold')\n",
        "plt.ylabel('Features', fontsize=12, fontweight='bold')\n",
        "plt.title('Top 15 Most Important Features - Decision Tree', fontsize=14, fontweight='bold')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.grid(axis='x', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Hyperparameter Tuning with Grid Search\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"HYPERPARAMETER TUNING WITH GRID SEARCH\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [3, 5, 7, 10, 15, 20, None],\n",
        "    'min_samples_split': [2, 5, 10, 20],\n",
        "    'min_samples_leaf': [1, 2, 4, 8],\n",
        "    'max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "print(\"\\nSearching for best hyperparameters...\")\n",
        "print(f\"Parameter grid: {param_grid}\")\n",
        "print(f\"This may take a few minutes...\\n\")\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(\n",
        "    DecisionTreeClassifier(random_state=42),\n",
        "    param_grid,\n",
        "    cv=5,\n",
        "    scoring='f1',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "start_time = time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "search_time = time() - start_time\n",
        "\n",
        "print(f\"\\n✓ Grid search completed in {search_time:.2f} seconds!\")\n",
        "print(f\"\\nBest parameters found:\")\n",
        "for param, value in grid_search.best_params_.items():\n",
        "    print(f\"  {param}: {value}\")\n",
        "print(f\"\\nBest cross-validation F1-score: {grid_search.best_score_:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Evaluate Optimized Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get best model from grid search\n",
        "best_dt_model = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions with the optimized model\n",
        "y_pred_optimized = best_dt_model.predict(X_test)\n",
        "y_pred_proba_optimized = best_dt_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate metrics for optimized model\n",
        "accuracy_opt = accuracy_score(y_test, y_pred_optimized)\n",
        "precision_opt = precision_score(y_test, y_pred_optimized)\n",
        "recall_opt = recall_score(y_test, y_pred_optimized)\n",
        "f1_opt = f1_score(y_test, y_pred_optimized)\n",
        "roc_auc_opt = roc_auc_score(y_test, y_pred_proba_optimized)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"OPTIMIZED DECISION TREE MODEL PERFORMANCE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nAccuracy:  {accuracy_opt:.4f} ({accuracy_opt*100:.2f}%)\")\n",
        "print(f\"Precision: {precision_opt:.4f} ({precision_opt*100:.2f}%)\")\n",
        "print(f\"Recall:    {recall_opt:.4f} ({recall_opt*100:.2f}%)\")\n",
        "print(f\"F1-Score:  {f1_opt:.4f} ({f1_opt*100:.2f}%)\")\n",
        "print(f\"ROC-AUC:   {roc_auc_opt:.4f} ({roc_auc_opt*100:.2f}%)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Print optimized tree structure\n",
        "print(f\"\\nOptimized Tree Structure:\")\n",
        "print(f\"  Number of Leaves: {best_dt_model.get_n_leaves()}\")\n",
        "print(f\"  Tree Depth: {best_dt_model.get_depth()}\")\n",
        "\n",
        "# Compare with the basic model\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PERFORMANCE COMPARISON\")\n",
        "print(\"=\"*60)\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC'],\n",
        "    'Basic DT': [accuracy, precision, recall, f1, roc_auc],\n",
        "    'Optimized DT': [accuracy_opt, precision_opt, recall_opt, f1_opt, roc_auc_opt],\n",
        "    'Improvement': [\n",
        "        accuracy_opt - accuracy,\n",
        "        precision_opt - precision,\n",
        "        recall_opt - recall,\n",
        "        f1_opt - f1,\n",
        "        roc_auc_opt - roc_auc\n",
        "    ]\n",
        "})\n",
        "print(comparison_df.to_string(index=False))\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Visualize Performance Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comparison visualization\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']\n",
        "basic_scores = [accuracy, precision, recall, f1, roc_auc]\n",
        "optimized_scores = [accuracy_opt, precision_opt, recall_opt, f1_opt, roc_auc_opt]\n",
        "\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "bars1 = ax.bar(x - width/2, basic_scores, width, label='Basic Decision Tree', color='#e67e22')\n",
        "bars2 = ax.bar(x + width/2, optimized_scores, width, label='Optimized Decision Tree', color='#27ae60')\n",
        "\n",
        "ax.set_xlabel('Metrics', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Basic vs Optimized Decision Tree Performance', fontsize=14, fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(metrics)\n",
        "ax.legend(fontsize=11)\n",
        "ax.set_ylim([0.85, 1.0])\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Add value labels on bars\n",
        "for bars in [bars1, bars2]:\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{height:.3f}',\n",
        "                ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Visualize Optimized Decision Tree\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the decision tree structure\n",
        "plt.figure(figsize=(20, 12))\n",
        "plot_tree(best_dt_model, \n",
        "          feature_names=feature_names,\n",
        "          class_names=['Benign', 'Malignant'],\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          fontsize=10)\n",
        "plt.title('Optimized Decision Tree Structure', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nNote: If the tree is too deep, the visualization may be hard to read.\")\n",
        "print(\"Consider using a smaller max_depth for better visualization.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Feature Importance - Optimized Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get feature importances from optimized model\n",
        "feature_importances_opt = pd.DataFrame({\n",
        "    'feature': feature_names,\n",
        "    'importance': best_dt_model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FEATURE IMPORTANCE - OPTIMIZED MODEL\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nTop 10 Most Important Features:\")\n",
        "print(feature_importances_opt.head(10).to_string(index=False))\n",
        "\n",
        "# Visualize top 15 features\n",
        "plt.figure(figsize=(12, 8))\n",
        "top_features_opt = feature_importances_opt.head(15)\n",
        "plt.barh(range(len(top_features_opt)), top_features_opt['importance'], color='#16a085')\n",
        "plt.yticks(range(len(top_features_opt)), top_features_opt['feature'])\n",
        "plt.xlabel('Importance', fontsize=12, fontweight='bold')\n",
        "plt.ylabel('Features', fontsize=12, fontweight='bold')\n",
        "plt.title('Top 15 Most Important Features - Optimized Decision Tree', fontsize=14, fontweight='bold')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.grid(axis='x', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Save the Best Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create models directory if it doesn't exist\n",
        "os.makedirs('models', exist_ok=True)\n",
        "\n",
        "# Save the optimized model\n",
        "model_filename = 'models/decision_tree_breast_cancer_model.pkl'\n",
        "joblib.dump(best_dt_model, model_filename)\n",
        "\n",
        "# Save model metadata\n",
        "metadata = {\n",
        "    'model_type': 'Decision Tree Classifier',\n",
        "    'criterion': best_dt_model.criterion,\n",
        "    'max_depth': best_dt_model.max_depth,\n",
        "    'min_samples_split': best_dt_model.min_samples_split,\n",
        "    'min_samples_leaf': best_dt_model.min_samples_leaf,\n",
        "    'max_features': best_dt_model.max_features,\n",
        "    'n_leaves': best_dt_model.get_n_leaves(),\n",
        "    'tree_depth': best_dt_model.get_depth(),\n",
        "    'accuracy': accuracy_opt,\n",
        "    'precision': precision_opt,\n",
        "    'recall': recall_opt,\n",
        "    'f1_score': f1_opt,\n",
        "    'roc_auc': roc_auc_opt,\n",
        "    'training_samples': len(X_train),\n",
        "    'testing_samples': len(X_test),\n",
        "    'features': X_train.shape[1]\n",
        "}\n",
        "\n",
        "metadata_filename = 'models/decision_tree_model_metadata.pkl'\n",
        "joblib.dump(metadata, metadata_filename)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MODEL SAVED SUCCESSFULLY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"✓ Model saved to: {model_filename}\")\n",
        "print(f\"✓ Metadata saved to: {metadata_filename}\")\n",
        "print(\"\\nModel Summary:\")\n",
        "for key, value in metadata.items():\n",
        "    if isinstance(value, float):\n",
        "        print(f\"  {key}: {value:.4f}\")\n",
        "    else:\n",
        "        print(f\"  {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 15. Make Predictions on New Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_breast_cancer(features, model_path='models/decision_tree_breast_cancer_model.pkl', \n",
        "                          scaler_path='data/processed/scaler.pkl'):\n",
        "    \"\"\"\n",
        "    Predict breast cancer diagnosis for a new patient using Decision Tree.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    features : array-like\n",
        "        Array of 30 feature values (must be in original scale, not scaled)\n",
        "    model_path : str\n",
        "        Path to the saved Decision Tree model\n",
        "    scaler_path : str\n",
        "        Path to the saved scaler\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    prediction : int\n",
        "        0 for Benign, 1 for Malignant\n",
        "    probability : array\n",
        "        Probability for each class [P(Benign), P(Malignant)]\n",
        "    \"\"\"\n",
        "    # Load model and scaler\n",
        "    model = joblib.load(model_path)\n",
        "    scaler = joblib.load(scaler_path)\n",
        "    \n",
        "    # Reshape features if needed\n",
        "    if len(features) == 30:\n",
        "        features = np.array(features).reshape(1, -1)\n",
        "    \n",
        "    # Scale features\n",
        "    features_scaled = scaler.transform(features)\n",
        "    \n",
        "    # Make prediction\n",
        "    prediction = model.predict(features_scaled)[0]\n",
        "    probability = model.predict_proba(features_scaled)[0]\n",
        "    \n",
        "    # Interpret result\n",
        "    diagnosis = \"Malignant (Cancer)\" if prediction == 1 else \"Benign (No Cancer)\"\n",
        "    confidence = probability[prediction] * 100\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"PREDICTION RESULT (Decision Tree)\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Diagnosis: {diagnosis}\")\n",
        "    print(f\"Confidence: {confidence:.2f}%\")\n",
        "    print(f\"\\nProbabilities:\")\n",
        "    print(f\"  Benign:    {probability[0]*100:.2f}%\")\n",
        "    print(f\"  Malignant: {probability[1]*100:.2f}%\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    return prediction, probability\n",
        "\n",
        "\n",
        "# Test with a sample from test set\n",
        "print(\"\\nTesting prediction function with a sample from test set:\")\n",
        "sample_features = X_test.iloc[0].values\n",
        "actual_label = \"Malignant\" if y_test[0] == 1 else \"Benign\"\n",
        "print(f\"Actual diagnosis: {actual_label}\")\n",
        "\n",
        "prediction, probability = predict_breast_cancer(sample_features)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook trained and evaluated a Decision Tree classifier on the UCI Breast Cancer dataset.\n",
        "\n",
        "### Key Advantages of Decision Trees:\n",
        "1. **Interpretability**: Easy to understand and visualize\n",
        "2. **Feature Importance**: Automatically identifies most important features\n",
        "3. **No Feature Scaling Required**: Works with raw or scaled data\n",
        "4. **Fast Training**: Quick to train and predict\n",
        "\n",
        "### Key Disadvantages:\n",
        "1. **Overfitting**: Prone to overfitting without proper pruning\n",
        "2. **Instability**: Small changes in data can lead to different trees\n",
        "3. **Bias**: Can be biased toward features with more levels\n",
        "\n",
        "### Next Steps:\n",
        "- Consider ensemble methods (Random Forest, Gradient Boosting) for better performance\n",
        "- Compare Decision Tree performance with SVM and other models\n",
        "- Experiment with different hyperparameter combinations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
